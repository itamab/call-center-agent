{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cd66e8",
   "metadata": {},
   "source": [
    "# Call center agent - based on LangMem memory extractor\n",
    "\n",
    "Call center agent supports voice interactions using:\n",
    "- [OpenAI's Whisper](https://platform.openai.com/docs/guides/speech-to-text) for speech-to-text\n",
    "- [Kokoro](https://huggingface.co/spaces/hexgrad/Kokoro-TTS) for text-to-speech\n",
    "\n",
    "LangMem memory manager is used to collect and track information given by the user during the call\n",
    "\n",
    "![call_center_agent_flow.png](call_center_agent_flow.png)\n",
    "\n",
    "### Install dependencies\n",
    "\n",
    "Ensure you have `ffmpeg` installed. \n",
    "\n",
    "On linux, you can install it with: \\\n",
    "sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U numpy==2.1.0 scipy openai kokoro langchain-core langgraph langchain-openai langmem openai-whisper pydantic email-validator sounddevice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2166a-897b-4d89-b1df-b64a84d11cea",
   "metadata": {},
   "source": [
    "### Global Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a655fb-f727-412b-8ec1-0e5f5e48cdf5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b39e8-440b-4b1d-9a49-b813a91a7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, Optional, List\n",
    "import io\n",
    "import threading\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.display import Image, display, Audio\n",
    "from openai import OpenAI\n",
    "from kokoro import KPipeline\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langmem import create_memory_manager\n",
    "from langmem.knowledge.extraction import MemoryManager\n",
    "from email.message import EmailMessage\n",
    "import time\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "#import smtplib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b724c3",
   "metadata": {},
   "source": [
    "### Set environment variables\n",
    "\n",
    "* Set your `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7311ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # Check if the variable is set in the OS environment\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # If not set, prompt the user for input\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "    \n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8376d3-f90c-4554-9856-72da0851ee35",
   "metadata": {},
   "source": [
    "#### Models initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2db77a-d6d5-4f06-bb69-ded34b6ec970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat model\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Initialize kokoro TTS pipeline\n",
    "kpipeline = KPipeline(lang_code='a')\n",
    "\n",
    "# Initialize whisper STT model\n",
    "whisper_model = whisper.load_model(\"medium.en\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddfd7a-fcbc-4f5a-b39c-50e5a39ae9dc",
   "metadata": {},
   "source": [
    "#### Chatbot instructions and messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970c767-a8df-45a4-8eec-016c5f0a49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling and tracking the user request form \n",
    "FORM_FILL_SYSTEM_MESSAGE = \"\"\"You are a helpful call center agent. \n",
    "\n",
    "Your task is to fill a user request form by asking the user to provide necessary information.\n",
    "\n",
    "Here is the current user request form (may be empty if no information has been provided yet):\n",
    "<user_request_form>\n",
    "{request_form}\n",
    "</user_request_form>\n",
    "\n",
    "Ask for one form detail at each iteration.\n",
    "\n",
    "If the request form was completed then reply \"Got it!\".\n",
    "\"\"\"\n",
    "\n",
    "# Checking if form completed\n",
    "FORM_COMPLETION_STATUS_SYSTEM_MESSAGE = \"\"\"You are a helpful call center agent. \n",
    "\n",
    "Your task is to decide if a user request form is completed.\n",
    "\n",
    "Here is the current user request form (may be empty if no information has been provided yet):\n",
    "<user_request_form>\n",
    "{request_form}\n",
    "</user_request_form>\n",
    "\"\"\"\n",
    "\n",
    "# Checking if form is valid\n",
    "FORM_FIX_SYSTEM_MESSAGE = \"\"\"You are a helpful call center agent. \n",
    "\n",
    "Your task is to detect in the following user request form in which field there might be a problem:\n",
    "\n",
    "Here is the current user request form (may be empty if no information has been provided yet):\n",
    "<user_request_form>\n",
    "{request_form}\n",
    "</user_request_form>\n",
    "\"\"\"\n",
    "\n",
    "# A message asking the user to approve form details\n",
    "APPROVE_MESSAGE = \"\"\"Please reply 'yes' to confirm the details below, or 'no' if you want to make changes:\n",
    "**********************\n",
    "{request_form}\n",
    "**********************\n",
    "\"\"\"\n",
    "\n",
    "# Welcome message\n",
    "WELCOME_MESSAGE = \"Welcome to automated call center!\"\n",
    "\n",
    "# Respond when user asks to change something in the form\n",
    "CHANGE_MESSAGE = \"What changes would you like to make?\"\n",
    "\n",
    "# Temp file for audio recording\n",
    "AUDIO_PATH = './audio.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e988a-d0a8-451b-a7bf-47462c47d1c1",
   "metadata": {},
   "source": [
    "#### Audio utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d42dc-3968-4955-92ae-dc44bf5bf3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioUtils:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.calibrate_mic()        \n",
    "\n",
    "    def calibrate_mic(self):\n",
    "        mean_seq = []\n",
    "        with sd.InputStream(samplerate=16000, channels=1, dtype='int16') as stream:\n",
    "            for _ in range(50):\n",
    "                audio_chunk, _ = stream.read(1024)  # Read audio data in chunks\n",
    "                mean_seq.append(np.mean(np.abs(audio_chunk)))\n",
    "\n",
    "        mean_seq = mean_seq[10:]\n",
    "        self.silence_mean_threshold = 1.5*np.mean(mean_seq)\n",
    "                \n",
    "    def play_audio(self, response: str):\n",
    "        \"\"\"Play an audio of the response with Kokoro.\"\"\"\n",
    "            \n",
    "        generator = kpipeline(\n",
    "            response, voice='af_heart', # <= change voice here\n",
    "            speed=1, split_pattern=r'\\n+'\n",
    "        )\n",
    "    \n",
    "        for i, (gs, ps, audio) in enumerate(generator):            \n",
    "            display(Audio(data=audio, rate=24000, autoplay=i==0))\n",
    "            time.sleep(len(audio)/24000)\n",
    "            break    \n",
    "    \n",
    "    def record_audio_until_stop(self):\n",
    "        \"\"\"Records audio from the microphone until Enter is pressed, then saves it to a .wav file.\"\"\"        \n",
    "\n",
    "        audio_data = []  # List to store audio chunks\n",
    "        recording = True  # Flag to control recording\n",
    "        sample_rate = 16000 # (kHz) Adequate for human voice frequency\n",
    "    \n",
    "        def record_audio():\n",
    "            \"\"\"Continuously records audio until the recording flag is set to False.\"\"\"\n",
    "            nonlocal audio_data, recording\n",
    "            with sd.InputStream(samplerate=sample_rate, channels=1, dtype='int16') as stream:\n",
    "                print(\"Recording...\")\n",
    "                while recording:\n",
    "                    audio_chunk, _ = stream.read(1024)  # Read audio data in chunks\n",
    "                    audio_data.append(audio_chunk)                                                \n",
    "    \n",
    "        def stop_recording():\n",
    "            \"\"\"Waits for user input to stop the recording.\"\"\"\n",
    "    \n",
    "            started_talking = False\n",
    "            \n",
    "            while True:\n",
    "                \n",
    "                silent = True\n",
    "\n",
    "                if len(audio_data) < 11:\n",
    "                    continue\n",
    "                                        \n",
    "                for last_audio_chunk in audio_data[-10:]:                    \n",
    "                    if np.mean(np.abs(last_audio_chunk)) > self.silence_mean_threshold:\n",
    "                        silent = False \n",
    "                        started_talking = True\n",
    "        \n",
    "                if silent and started_talking:                \n",
    "                    break\n",
    "                                \n",
    "            nonlocal recording\n",
    "            recording = False\n",
    "    \n",
    "        # Start recording in a separate thread\n",
    "        recording_thread = threading.Thread(target=record_audio)\n",
    "        recording_thread.start()\n",
    "    \n",
    "        # Start a thread to listen for the Enter key\n",
    "        stop_thread = threading.Thread(target=stop_recording)\n",
    "        stop_thread.start()\n",
    "    \n",
    "        # Wait for both threads to complete\n",
    "        stop_thread.join()\n",
    "        recording_thread.join()\n",
    "    \n",
    "        # Stack all audio chunks into a single NumPy array and write to file\n",
    "        audio_data = np.concatenate(audio_data, axis=0)    \n",
    "        \n",
    "        # Convert to WAV format in-memory\n",
    "        audio_bytes = io.BytesIO()\n",
    "        write(audio_bytes, sample_rate, audio_data)  # Use scipy's write function to save to BytesIO\n",
    "        audio_bytes.seek(0)  # Go to the start of the BytesIO buffer\n",
    "        audio_bytes.name = AUDIO_PATH # Set a filename for the in-memory file\n",
    "        with open(audio_bytes.name, \"wb\") as f:\n",
    "            f.write(audio_bytes.getbuffer())\n",
    "    \n",
    "        return audio_data\n",
    "\n",
    "audioUtils = AudioUtils()\n",
    "print(f'audioUtils.silence_mean_threshold: {audioUtils.silence_mean_threshold}')\n",
    "\n",
    "def get_user_reply():\n",
    "    audioUtils.record_audio_until_stop() #input()    \n",
    "    user_reply = whisper_model.transcribe(AUDIO_PATH)\n",
    "    print(f\"user: {user_reply[\"text\"]}\")\n",
    "    return user_reply[\"text\"]\n",
    "\n",
    "def respond_to_user(txt):\n",
    "    print(f'assistant: {txt}')\n",
    "    audioUtils.play_audio(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850afa14-e0fd-400f-8955-89511795a3d3",
   "metadata": {},
   "source": [
    "### Graph definition\n",
    "\n",
    "![call_center_agent_graph.png](call_center_agent_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab219db2-ee01-4f97-bbe1-22706b3e6ef6",
   "metadata": {},
   "source": [
    "#### Structures definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52194bb-0604-46fa-a8f6-e3ebdab56921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form template\n",
    "class RequestForm(BaseModel): \n",
    "    \"\"\"User request form template\"\"\"\n",
    "    name: Optional[str] = Field(description=\"The user's name\", default=None)\n",
    "    email: Optional[EmailStr] = Field(description=\"The user's email address\", default=None)\n",
    "    request: Optional[str] = Field(description=\"The user's request\", default=None)    \n",
    "\n",
    "#LangGraph graph state\n",
    "class RequestState(MessagesState): \n",
    "    \"\"\"Graph state containing chat messages (inherited from MessagesState) and user request form managment variables\"\"\"\n",
    "    request_manager: MemoryManager = Field(description=\"Request form details extractor\", default=None)\n",
    "    request_form: RequestForm = Field(description=\"Request form details\", default=None)\n",
    "\n",
    "#Chatbot structured output for form completion status response\n",
    "class RequestFormStatus(TypedDict): \n",
    "    \"\"\"Decide if the user request form was completed\"\"\"\n",
    "    status: Literal['completed', 'not completed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fec2c2-ca97-4d06-bf0f-ca0c968885ff",
   "metadata": {},
   "source": [
    "#### Node definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start node - welcome message and graph state initialization\n",
    "def welcome_user(state: RequestState):\n",
    "    \"\"\"Play a welcome message to the user, initialize user request memory manager and form template.\"\"\"\n",
    "    \n",
    "    respond_to_user(WELCOME_MESSAGE)\n",
    "\n",
    "    request_manager = create_memory_manager(\n",
    "                        chat_model,\n",
    "                        schemas=[RequestForm],                    \n",
    "                        enable_inserts=False,  # Profiles update in-place \n",
    "                      )\n",
    "\n",
    "    request_form = RequestForm()\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=WELCOME_MESSAGE)], \"request_manager\": request_manager, \"request_form\": request_form}\n",
    "\n",
    "\n",
    "#form update node (loop untill form completion)\n",
    "def update_form(state: RequestState):\n",
    "    \"\"\"Reflect on chat history and update the request form with new details\"\"\"\n",
    "\n",
    "    new_messages = []\n",
    "    user_messages = [message for message in state[\"messages\"] if type(message) == HumanMessage]    \n",
    "    \n",
    "    #get user reply for previous assistant message\n",
    "    if len(state[\"messages\"]) > 1:\n",
    "        user_reply = get_user_reply()\n",
    "        user_messages.append(HumanMessage(user_reply))\n",
    "        new_messages.append(HumanMessage(user_reply))\n",
    "    \n",
    "    #update user request form   \n",
    "    request_form = state[\"request_form\"] \n",
    "    if (len(user_messages) > 0): #update request form with new user provided data        \n",
    "        request_form = state[\"request_manager\"].invoke({\"messages\": user_messages})[0].content\n",
    "        print(f'request_form:\\n{request_form}')\n",
    "        \n",
    "    #ask user for more details if necessary\n",
    "    system_msg = FORM_FILL_SYSTEM_MESSAGE.format(request_form=request_form)        \n",
    "    response = chat_model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"] + new_messages)\n",
    "    respond_to_user(response.content)\n",
    "\n",
    "    new_messages.append(response)\n",
    "\n",
    "    return {\"messages\": new_messages, \"request_form\": request_form}\n",
    "\n",
    "\n",
    "#fix form details node (loop untill form completion)\n",
    "def change_form(state: RequestState):\n",
    "    \"\"\"Reflect on chat history and update the request form with new details\"\"\"\n",
    "\n",
    "    respond_to_user(CHANGE_MESSAGE)\n",
    "\n",
    "    user_reply = get_user_reply()\n",
    "    \n",
    "    user_messages = [message for message in state[\"messages\"] if type(message) == HumanMessage]\n",
    "    user_messages.append(HumanMessage(user_reply))\n",
    "    \n",
    "    #update user request form   \n",
    "    request_form = state[\"request_form\"] \n",
    "    if (len(user_messages) > 0): #update request form with new user provided data        \n",
    "        request_form = state[\"request_manager\"].invoke({\"messages\": user_messages})[0].content                \n",
    "        print(f'request_form:\\n{request_form}')\n",
    "\n",
    "    return {\"messages\": user_reply, \"request_form\": request_form}\n",
    "\n",
    "\n",
    "def fix_form(state: RequestState):\n",
    "    \"\"\"Reflect on chat history and fix the request form with correct details\"\"\"\n",
    "\n",
    "    request_form = state[\"request_form\"] \n",
    "    \n",
    "    #ask user to fix form details if necessary\n",
    "    system_msg = FORM_FIX_SYSTEM_MESSAGE.format(request_form=request_form)        \n",
    "    response = chat_model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "    new_messages = [response]\n",
    "    \n",
    "    respond_to_user(response.content)    \n",
    "    \n",
    "    #update user request form   \n",
    "    user_messages = [message for message in state[\"messages\"] if type(message) == HumanMessage]\n",
    "    user_reply = get_user_reply()\n",
    "    user_messages.append(HumanMessage(user_reply))    \n",
    "    \n",
    "    request_form = state[\"request_manager\"].invoke({\"messages\": user_messages})[0].content\n",
    "    print(f'request_form:\\n{request_form}')\n",
    "\n",
    "    new_messages.append(HumanMessage(user_reply))\n",
    "    \n",
    "    return {\"messages\": new_messages, \"request_form\": request_form}\n",
    "    \n",
    "\n",
    "#form completion check node\n",
    "def check_form_completion(state: RequestState):\n",
    "    \"\"\"Decide whether to route the user to confirm form details or to continue filling the form\"\"\"\n",
    "\n",
    "    request_form = state[\"request_form\"]\n",
    "\n",
    "    if request_form.name is None or request_form.email is None or request_form.request is None:\n",
    "        return \"update_form\"\n",
    "    else:\n",
    "        #use chat model to decide if form was completed or further corrections are needed\n",
    "        system_msg = FORM_COMPLETION_STATUS_SYSTEM_MESSAGE.format(request_form=request_form)            \n",
    "        response = chat_model.with_structured_output(RequestFormStatus).invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "        if response['status'] != 'completed':\n",
    "            print(f\"check_form_completion: chatbot thinks form is missing details: response['status']: {response['status']}\\n{request_form}\")\n",
    "            return \"fix_form\"\n",
    "        \n",
    "        return \"get_user_confirmation\"\n",
    "\n",
    "\n",
    "#ask user to approve form details\n",
    "def get_user_confirmation(state: RequestState):\n",
    "    \"\"\"Get request details confirmation from user\"\"\"\n",
    "\n",
    "    request_form = state[\"request_form\"]    \n",
    "    \n",
    "    response = APPROVE_MESSAGE.format(request_form=request_form)\n",
    "    \n",
    "    respond_to_user(response)\n",
    "    \n",
    "    user_reply = get_user_reply()\n",
    "\n",
    "    return {\"messages\": [response, HumanMessage(user_reply)]}\n",
    "\n",
    "\n",
    "#Check if user approved form details and route accordingly \n",
    "def check_form_confirmation(state: RequestState):\n",
    "    \"\"\"Decide whether to open user request or continue filling the form\"\"\"\n",
    "\n",
    "    user_reply = state[\"messages\"][-1:][0].content.lower()\n",
    "\n",
    "    print(f'user_reply: {user_reply}')\n",
    "\n",
    "    if 'yes' in user_reply: #user approved form details by replying 'yes'\n",
    "        return \"open_user_request\"\n",
    "    elif 'no' in user_reply:        \n",
    "        return \"change_form\"\n",
    "    else:\n",
    "        return \"get_user_confirmation\"\n",
    "\n",
    "\n",
    "#Continue with openning the user request and sending a notification\n",
    "def open_user_request(state: RequestState):\n",
    "\n",
    "    request_form = state[\"request_form\"]\n",
    "\n",
    "    emsg = EmailMessage()\n",
    "    emsg.set_content(request_form.request)\n",
    "    emsg['Subject'] = f'Call Center - request by {request_form.name} is being processed'\n",
    "    emsg['From'] = 'localhost' #your SMTP server address\n",
    "    emsg['To'] = request_form.email\n",
    "    \n",
    "    # Send the message via our own SMTP server.\n",
    "    print(f'\\n***********\\nNotification Email:\\n{emsg}***********') #s = smtplib.SMTP('localhost'); s.send_message(msg); s.quit()\n",
    "\n",
    "    respond_to_user(f'A request was opened for you. A notification was sent to your email. Have a good day!')    \n",
    "    \n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(RequestState)\n",
    "\n",
    "builder.add_node(\"welcome_user\", welcome_user)\n",
    "builder.add_node(\"update_form\", update_form)\n",
    "builder.add_node(\"check_form_completion\", check_form_completion)\n",
    "builder.add_node(\"get_user_confirmation\", get_user_confirmation)\n",
    "builder.add_node(\"check_form_confirmation\", check_form_confirmation)\n",
    "builder.add_node(\"change_form\", change_form)\n",
    "builder.add_node(\"fix_form\", fix_form)\n",
    "builder.add_node(\"open_user_request\", open_user_request)\n",
    "\n",
    "builder.add_edge(START, \"welcome_user\")\n",
    "builder.add_edge(\"welcome_user\", \"update_form\")\n",
    "builder.add_conditional_edges(\"update_form\", check_form_completion)\n",
    "builder.add_conditional_edges(\"change_form\", check_form_completion)\n",
    "builder.add_conditional_edges(\"fix_form\", check_form_completion)\n",
    "builder.add_conditional_edges(\"get_user_confirmation\", check_form_confirmation)\n",
    "builder.add_edge(\"open_user_request\", END)\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "call_center_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c245a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = call_center_graph.invoke({\"messages\": []})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
